{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[29],{425:function(e,t,a){\"use strict\";a.r(t);var s=a(2),n=Object(s.a)({},(function(){var e=this,t=e.$createElement,a=e._self._c||t;return a(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":e.$parent.slotKey}},[a(\"p\"),a(\"div\",{staticClass:\"table-of-contents\"},[a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"#前言\"}},[e._v(\"前言\")])]),a(\"li\",[a(\"a\",{attrs:{href:\"#mmpose\"}},[e._v(\"MMPose\")]),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"#整体基本框架\"}},[e._v(\"整体基本框架\")])]),a(\"li\",[a(\"a\",{attrs:{href:\"#mmpose-整体构建流程和思想\"}},[e._v(\"MMPose 整体构建流程和思想\")])]),a(\"li\",[a(\"a\",{attrs:{href:\"#mmpose可与openmmlab-成员无缝对接，贯通视觉感知上下游\"}},[e._v(\"mmpose可与OpenMMLab 成员无缝对接，贯通视觉感知上下游\")])])])])])]),a(\"p\"),e._v(\" \"),a(\"h2\",{attrs:{id:\"前言\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#前言\"}},[e._v(\"#\")]),e._v(\" 前言\")]),e._v(\" \"),a(\"p\",[e._v(\"MMPose 是一个基于 PyTorch 的姿态估计工具箱，于 2020 年 7 月 OpenMMLab 正式对外开源，是本领域目前功能最全，涵盖算法最多的开源算法库。\")]),e._v(\" \"),a(\"p\",[e._v(\"Github地址：\"),a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmpose\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"https://github.com/open-mmlab/mmpose\"),a(\"OutboundLink\")],1)]),e._v(\" \"),a(\"p\",[e._v(\"目前 MMPose 已经支持了十七余种姿态估计领域算法实现，涵盖了2D多人姿态估计、2D手部姿态估计、2D人脸关键点检测、133关键点的全身人体姿态估计、3D人体形状恢复、服饰关键点检测、动物关键点检测等子任务； 支持了30余个常用学术数据集，提供统一的接口和便捷的预处理脚本或指引文档； 提供了姿态估计中常用的AP、PCK、AUC、MPJPE等评价指标。\")]),e._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://gitee.com/Lj_Evan/images/raw/master/mmpose/20211026005108.png\",alt:\"MMPose\"}})]),e._v(\" \"),a(\"p\",[e._v(\"本文主要是从MMPose整体框架构建角度来解析，希望通过本文可以对MMPose整体构建流程和思想，核心组件划分，核心组件功能有一个大概的认识。\")]),e._v(\" \"),a(\"h2\",{attrs:{id:\"mmpose\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mmpose\"}},[e._v(\"#\")]),e._v(\" MMPose\")]),e._v(\" \"),a(\"h3\",{attrs:{id:\"整体基本框架\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#整体基本框架\"}},[e._v(\"#\")]),e._v(\" 整体基本框架\")]),e._v(\" \"),a(\"p\",[e._v(\"MMPose 延续了 OpenMMLab 系列代码库的基因，采用模块化设计，将统一的人体姿态分析框架解耦成不同的模块组件，通过组合不同的模块组件，可以便捷地构建自定义的人体姿态分析模型。\")]),e._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://gitee.com/Lj_Evan/images/raw/master/mmpose/20211026013528.png\",alt:\"image-20211026013528548\"}})]),e._v(\" \"),a(\"h3\",{attrs:{id:\"mmpose-整体构建流程和思想\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mmpose-整体构建流程和思想\"}},[e._v(\"#\")]),e._v(\" MMPose 整体构建流程和思想\")]),e._v(\" \"),a(\"p\",[a(\"img\",{attrs:{src:\"https://gitee.com/Lj_Evan/images/raw/master/mmpose/20211026020438.png\",alt:\"image-20211026020438229\"}})]),e._v(\" \"),a(\"h4\",{attrs:{id:\"基本组件\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#基本组件\"}},[e._v(\"#\")]),e._v(\" 基本组件\")]),e._v(\" \"),a(\"ul\",[a(\"li\",[e._v(\"dataloader:MMPose 提供了若干数据集接口，并使用流水线机制完成数据预处理\")]),e._v(\" \"),a(\"li\",[e._v(\"mmposemodel:MMPose 将模型结构划分为 Backbone、Neck、Head 等功能模块，并利用注册器和构建器实现各模块的配置、使用和扩展\")]),e._v(\" \"),a(\"li\",[e._v(\"builder:MMPose 基于 MMCV 提供的底层数据 I/O 和模型训练接口，通过配置文件实现对模型训练、推理的全流程管理；\")]),e._v(\" \"),a(\"li\",[e._v(\"detectors、misc、loss\")])]),e._v(\" \"),a(\"h5\",{attrs:{id:\"dataset、pipelines\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#dataset、pipelines\"}},[e._v(\"#\")]),e._v(\" dataset、pipelines\")]),e._v(\" \"),a(\"p\",[e._v(\"数据集相关的一些配置：\")]),e._v(\" \"),a(\"p\",[e._v(\"https://github.com/open-mmlab/mmpose/tree/master/mmpose/datasets\")]),e._v(\" \"),a(\"p\",[e._v(\"数据预处理的pipeline主要由以下几个步骤组成：\")]),e._v(\" \"),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/823d3d2560f1b28d5a9c51e88db4084e59076b30/mmpose/datasets/pipelines/loading.py%23L7\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"LoadImageFromFile\"),a(\"OutboundLink\")],1),e._v(\"：读取图片。\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/019afad329bec10957377129bcea23796eeba4f6/mmpose/datasets/pipelines/bottom_up_transform.py%23L362\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"BottomUpRandomAffine\"),a(\"OutboundLink\")],1),e._v(\"：随机仿射变换。\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/019afad329bec10957377129bcea23796eeba4f6/mmpose/datasets/pipelines/bottom_up_transform.py%23L328\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"BottomUpRandomFlip\"),a(\"OutboundLink\")],1),e._v(\"：随机水平翻转 。\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/823d3d2560f1b28d5a9c51e88db4084e59076b30/mmpose/datasets/pipelines/shared_transform.py%23L20\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"ToTensor\"),a(\"OutboundLink\")],1),e._v(\"：图片转换为Tensor。\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/823d3d2560f1b28d5a9c51e88db4084e59076b30/mmpose/datasets/pipelines/shared_transform.py%23L35\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"NormalizeTensor\"),a(\"OutboundLink\")],1),e._v(\"：输入Tensor归一化，减均值，除方差。\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/019afad329bec10957377129bcea23796eeba4f6/mmpose/datasets/pipelines/bottom_up_transform.py%23L550\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"BottomUpGenerateTarget\"),a(\"OutboundLink\")],1),e._v(\"：根据标签，生成所需GT。\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://link.zhihu.com/?target=https%3A//github.com/open-mmlab/mmpose/blob/823d3d2560f1b28d5a9c51e88db4084e59076b30/mmpose/datasets/pipelines/shared_transform.py%23L102\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"Collect\"),a(\"OutboundLink\")],1),e._v(\"：整合训练中需要用到的数据。\")])]),e._v(\" \"),a(\"h5\",{attrs:{id:\"backbone\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#backbone\"}},[e._v(\"#\")]),e._v(\" Backbone\")]),e._v(\" \"),a(\"p\",[e._v(\"MMPose 中已经集成了部分骨架网络，具体见文件夹：\"),a(\"code\",[e._v(\"mmpose/models/backbones\")]),e._v(\"，已经实现的骨架如下：\")]),e._v(\" \"),a(\"div\",{staticClass:\"language- line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[e._v(\"__all__ = [\\n    'AlexNet', 'HourglassNet', 'HourglassAENet', 'HRNet', 'MobileNetV2',\\n    'MobileNetV3', 'RegNet', 'ResNet', 'ResNetV1d', 'ResNeXt', 'SCNet',\\n    'SEResNet', 'SEResNeXt', 'ShuffleNetV1', 'ShuffleNetV2', 'CPM', 'RSN',\\n    'MSPN', 'ResNeSt', 'VGG', 'TCN', 'ViPNAS_ResNet', 'LiteHRNet'\\n]\\n\")])]),e._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),a(\"br\")])]),a(\"h5\",{attrs:{id:\"neck\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#neck\"}},[e._v(\"#\")]),e._v(\" Neck\")]),e._v(\" \"),a(\"p\",[e._v(\"具体可见文件夹：\"),a(\"code\",[e._v(\"mmpose/models/necks\")]),e._v(\"， MMPose 中已经实现的necks如下：\")]),e._v(\" \"),a(\"div\",{staticClass:\"language- line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[e._v(\"__all__ = ['GlobalAveragePooling']\\n\")])]),e._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),a(\"br\")])]),a(\"h5\",{attrs:{id:\"head\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#head\"}},[e._v(\"#\")]),e._v(\" Head\")]),e._v(\" \"),a(\"p\",[e._v(\"具体可见文件夹：\"),a(\"code\",[e._v(\"mmpose/models/heads\")]),e._v(\"， MMPose 中已经实现的heads如下：\")]),e._v(\" \"),a(\"div\",{staticClass:\"language- line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[e._v(\"__all__ = [\\n    'TopdownHeatmapSimpleHead', 'TopdownHeatmapMultiStageHead',\\n    'TopdownHeatmapMSMUHead', 'TopdownHeatmapBaseHead',\\n    'AEHigherResolutionHead', 'AESimpleHead', 'AEMultiStageHead',\\n    'DeepposeRegressionHead', 'TemporalRegressionHead', 'Interhand3DHead',\\n    'HMRMeshHead', 'DeconvHead', 'ViPNASHeatmapSimpleHead'\\n]\\n\")])]),e._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"7\")]),a(\"br\")])]),a(\"h5\",{attrs:{id:\"detectors\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#detectors\"}},[e._v(\"#\")]),e._v(\" detectors\")]),e._v(\" \"),a(\"p\",[e._v(\"检测器，MMPose 中已经实现的如下：\")]),e._v(\" \"),a(\"div\",{staticClass:\"language- line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[e._v(\"__all__ = [\\n    'TopDown', 'AssociativeEmbedding', 'ParametricMesh', 'MultiTask',\\n    'PoseLifter', 'Interhand3D'\\n]\\n\")])]),e._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),a(\"br\")])]),a(\"h5\",{attrs:{id:\"loss\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#loss\"}},[e._v(\"#\")]),e._v(\" loss\")]),e._v(\" \"),a(\"p\",[e._v(\"非常多的 loss，放心食用\")]),e._v(\" \"),a(\"div\",{staticClass:\"language- line-numbers-mode\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[a(\"code\",[e._v(\"\\n__all__ = [\\n    'JointsMSELoss', 'JointsOHKMMSELoss', 'HeatmapLoss', 'AELoss',\\n    'MultiLossFactory', 'MeshLoss', 'GANLoss', 'SmoothL1Loss', 'WingLoss',\\n    'MPJPELoss', 'MSELoss', 'L1Loss', 'BCELoss', 'BoneLoss',\\n    'SemiSupervisionLoss'\\n]\\n\")])]),e._v(\" \"),a(\"div\",{staticClass:\"line-numbers-wrapper\"},[a(\"span\",{staticClass:\"line-number\"},[e._v(\"1\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"2\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"3\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"4\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"5\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"6\")]),a(\"br\"),a(\"span\",{staticClass:\"line-number\"},[e._v(\"7\")]),a(\"br\")])]),a(\"p\",[a(\"strong\",[e._v(\"training tricks\")])]),e._v(\" \"),a(\"p\",[e._v(\"目前由于对姿态估计方面知识储备太少了，还没有太多的理解，后面同步补充（手动狗头）\")]),e._v(\" \"),a(\"h3\",{attrs:{id:\"mmpose可与openmmlab-成员无缝对接，贯通视觉感知上下游\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#mmpose可与openmmlab-成员无缝对接，贯通视觉感知上下游\"}},[e._v(\"#\")]),e._v(\" mmpose可与OpenMMLab 成员无缝对接，贯通视觉感知上下游\")]),e._v(\" \"),a(\"p\",[e._v(\"（顺便预告一个基于mmdet与mmpose结合的类AR小应用--Virtual_Keyboard）\")]),e._v(\" \"),a(\"ul\",[a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmcv\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMCV\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab foundational library for computer vision.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mim\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MIM\"),a(\"OutboundLink\")],1),e._v(\": MIM Installs OpenMMLab Packages.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmclassification\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMClassification\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab image classification toolbox and benchmark.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmdetection\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMDetection\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab detection toolbox and benchmark.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmdetection3d\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMDetection3D\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab next-generation platform for general 3D object detection.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmsegmentation\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMSegmentation\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab semantic segmentation toolbox and benchmark.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmaction2\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMAction2\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab next-generation action understanding toolbox and benchmark.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmtracking\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMTracking\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab video perception toolbox and benchmark.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmpose\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMPose\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab pose estimation toolbox and benchmark.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmediting\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMEditing\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab image and video editing toolbox.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmocr\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMOCR\"),a(\"OutboundLink\")],1),e._v(\": A Comprehensive Toolbox for Text Detection, Recognition and Understanding.\")]),e._v(\" \"),a(\"li\",[a(\"a\",{attrs:{href:\"https://github.com/open-mmlab/mmgeneration\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"MMGeneration\"),a(\"OutboundLink\")],1),e._v(\": OpenMMLab next-generation toolbox for generative models.\")])]),e._v(\" \"),a(\"h4\",{attrs:{id:\"ps-更多关于2d二维人体姿态估计mmpose实现解析\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#ps-更多关于2d二维人体姿态估计mmpose实现解析\"}},[e._v(\"#\")]),e._v(\" PS:更多关于2d二维人体姿态估计mmpose实现解析\")]),e._v(\" \"),a(\"p\",[a(\"a\",{attrs:{href:\"https://zhuanlan.zhihu.com/p/394060630\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"自顶向下的 2D 人体姿态估计\"),a(\"OutboundLink\")],1)]),e._v(\" \"),a(\"p\",[a(\"a\",{attrs:{href:\"https://zhuanlan.zhihu.com/p/394060630\",target:\"_blank\",rel:\"noopener noreferrer\"}},[e._v(\"自底向上二维人体姿态估计\"),a(\"OutboundLink\")],1)])])}),[],!1,null,null,null);t.default=n.exports}}]);","extractedComments":[]}